from langchain.agents import initialize_agent, AgentType
from langchain_ollama import OllamaLLM
from langchain.tools import Tool
from bs4 import BeautifulSoup

# ğŸ”¹ Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† ØµÙØ­Ø© ÙˆÙŠØ¨ Ù…Ø¹ÙŠÙ†Ø©
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

def scrape_page(url: str, text_limit: int = 1000):
    options = Options()
    options.add_argument("--headless")  # ØªØ´ØºÙŠÙ„ Ø¨Ø¯ÙˆÙ† ÙˆØ§Ø¬Ù‡Ø© Ø±Ø³ÙˆÙ…ÙŠØ©
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    try:
        driver.get(url)
        page_content = driver.page_source
        soup = BeautifulSoup(page_content, 'html.parser')
        return soup.get_text(separator=' ', strip=True)[:text_limit]
    finally:
        driver.quit()




# ğŸ”¹ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„ÙˆØ­ÙŠØ¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© (Web Scraper ÙÙ‚Ø·)
tools = [
    Tool(
        name="Web Scraper",
        func=scrape_page,
        description="ÙŠØ³ØªØ®Ø¯Ù… Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† ØµÙØ­Ø© ÙˆÙŠØ¨ Ù…Ø¹ÙŠÙ†Ø©. ÙŠØ¬Ø¨ ØªÙ…Ø±ÙŠØ± Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙØ­Ø©."
    )
]

# âœ… **Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬**
model_name = "mistral"
temperature = 0.7
top_p = 0.9

# ğŸ”¹ Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ollama
llm = OllamaLLM(model=model_name, temperature=temperature, top_p=top_p)

# ğŸ”¹ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ù…Ø¹ Ollama (Ø¨Ø¯ÙˆÙ† Site Search)
agent_executor = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    return_intermediate_steps=False  # Ù…Ù†Ø¹ ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ© ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠØ©
)

# ğŸ”¹ ØªØ¬Ø±Ø¨Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„ Ù…Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ù…ÙˆÙ‚Ø¹ Ù…Ø¹ÙŠÙ†
# ØªØ¬Ø±Ø¨Ø© Ø§Ù„ÙƒÙˆØ¯
url = "https://link.springer.com/"
content = scrape_page(url)
print(content)
